#Clonando o repositório da YOLOv5 do github e entrando no diretório
!git clone https://github.com/ultralytics/yolov5.git
%cd yolov5

#Instalando as dependências
!pip install -r requirements.txt

#Bibliotecas que foram utilizadas
import torch
import os
import json
import requests
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from google.colab import files
uploaded = files.upload()

#Desabilitando o W&B
os.environ["WANDB_MODE"] = "dryrun"

#Baixando o arquivo de anotações do COCO
!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
!unzip -q annotations_trainval2017.zip

#Definindo o caminho do JSON
COCO_file = "annotations/instances_train2017.json"
coco = COCO(COCO_file)

#Modelo pre-treinado da YOLOv5
!wget -O yolov5s.pt https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt

#Carregando o modelo YOLOv5 pré-treinado
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')

#Definindo as classes desejadas
classes_escolhidas = ["plant", "food-other"]

#Obtendo os IDs das classes no COCO
categoria_ids = coco.getCatIds(catNms=classes_escolhidas)

#Obtendo IDs das imagens que contêm essas classes
image_ids = []
for cat_id in categoria_ids:
    image_ids.extend(coco.getImgIds(catIds=cat_id))
image_ids = list(set(image_ids))

#Criando  o diretório para salvar as imagens
image_dir = "coco_custom_dataset/images"
os.makedirs(image_dir, exist_ok=True)

#Baixando as imagens associadas
for img_id in image_ids[:100]:  # Pegando apenas 100 imagens
    img_info = coco.loadImgs(img_id)[0]
    img_url = img_info['coco_url']
    img_name = os.path.join(image_dir, f"{img_id}.jpg")

    response = requests.get(img_url, stream=True)
    if response.status_code == 200:
        with open(img_name, 'wb') as f:
            for chunk in response.iter_content(1024):
                f.write(chunk)

#Criando diretório para salvar as anotações
label_dir = "coco_custom_dataset/labels"
os.makedirs(label_dir, exist_ok=True)

#Carregando os dados do COCO
with open(COCO_file, 'r') as f:
    coco_data = json.load(f)

#Criando um mapeamento de classes
class_map = {coco_data["categories"][i]["name"]: i for i in range(len(coco_data["categories"]))}

#Criando arquivos de anotações para cada imagem
for img_id in image_ids[:100]:
    img_info = coco.loadImgs(img_id)[0]
    ann_ids = coco.getAnnIds(imgIds=img_id, catIds=categoria_ids, iscrowd=False)
    anns = coco.loadAnns(ann_ids)

    #Criando arquivo .txt para cada imagem
    label_file = os.path.join(label_dir, img_info['file_name'].replace('.jpg', '.txt'))
    with open(label_file, 'w') as f:
        for ann in anns:
            bbox = ann["bbox"]
            x_center = (bbox[0] + bbox[2] / 2) / img_info['width']
            y_center = (bbox[1] + bbox[3] / 2) / img_info['height']
            width = bbox[2] / img_info['width']
            height = bbox[3] / img_info["height"]

            # Obtendo o ID da classe no COCO
            class_name = [k for k, v in class_map.items() if v == ann["category_id"]][0]
            class_id = classes_escolhidas.index(class_name)

            f.write(f"{class_id} {x_center} {y_center} {width} {height}\n")

#Criando o arquivo de configuração dataset.yaml
dataset_yaml = """\
train: coco_custom_dataset/images
val: coco_custom_dataset/images
nc: 2
names: ['plant', 'food-other']
"""
with open("dataset.yaml", "w") as f:
    f.write(dataset_yaml)

#Treinando o modelo sem W&B e sem logs indesejados
!python train.py --img 640 --batch 16 --epochs 100 --data dataset.yaml --weights yolov5s.pt --no-wandb --silent

#Testando o modelo treinado
!python detect.py --weights runs/train/exp/weights/best.pt --source caminho/para/imagem.jpg


#Nome do arquivo ultilizado
image_path = list(uploaded.keys())[0]

#Carregar e processar imagem
img = Image.open(image_path)

#Fazendo a detecção
results = model(img)
results.show()

#Salvando a imagem com as border boxing
results.save(save_dir='./')

#Exibe a imagem no colab
img_resultado = cv2.imread(f'./{image_path}')
img_resultado = cv2.cvtColor(img_resultado, cv2.COLOR_BGR2RGB)

plt.figure(figsize=(10, 5))
plt.imshow(img_resultado)
plt.axis('off')
plt.show()
